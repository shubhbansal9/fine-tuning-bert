{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0754ba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\shubh\\anaconda3\\lib\\site-packages (4.29.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\shubh\\anaconda3\\lib\\site-packages (2.13.2)\n",
      "Requirement already satisfied: torch in c:\\users\\shubh\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shubh\\anaconda3\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\shubh\\anaconda3\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: peft in c:\\users\\shubh\\anaconda3\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: pandas in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from peft) (0.31.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from peft) (5.8.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from scikit-learn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch scikit-learn matplotlib peft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c79f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\transformers\\adapters\\__init__.py:27: FutureWarning: The `adapter-transformers` package is deprecated and replaced by the `adapters` package. See https://docs.adapterhub.ml/transitioning.html.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48803dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'text', 'label', '__index_level_0__'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'text', 'label', '__index_level_0__'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Fake and True datasets\n",
    "fake_df = pd.read_csv('Fake.csv')\n",
    "true_df = pd.read_csv('True.csv')\n",
    "\n",
    "# Add label columns\n",
    "fake_df['label'] = 0\n",
    "true_df['label'] = 1\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "df = df[['title', 'text', 'label']].dropna()\n",
    "\n",
    "# Reduce dataset size for quicker training (optional)\n",
    "df = df.sample(n=10000, random_state=42)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3e96e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define tokenizer\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Function to tokenize data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6587a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)  # Convert logits to tensor\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': prec, 'recall': rec}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5d10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610605f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate model\n",
    "def train_and_evaluate(model, training_args, tokenized_datasets):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    eval_results = trainer.evaluate()\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    eval_results['train_time'] = train_time\n",
    "    eval_results['eval_time'] = eval_time\n",
    "    \n",
    "    return eval_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "524fcf9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: title, __index_level_0__, text. If title, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n",
      "  Number of trainable parameters = 66955010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 1:11:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Configuration saved in ./results\\checkpoint-500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: title, __index_level_0__, text. If title, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: title, __index_level_0__, text. If title, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 05:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Results: {'eval_loss': 0.0007199611281976104, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_runtime': 358.9839, 'eval_samples_per_second': 5.571, 'eval_steps_per_second': 0.348, 'epoch': 1.0, 'train_time': 4267.570960044861, 'eval_time': 358.9839472770691}\n"
     ]
    }
   ],
   "source": [
    "# Base Model without Soft Prompts or LoRA\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)\n",
    "base_results = train_and_evaluate(base_model, training_args, tokenized_datasets)\n",
    "print(\"Base Model Results:\", base_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526bae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SoftPromptModel(AutoModelForSequenceClassification):\n",
    "    def __init__(self, config, num_labels, soft_prompt_length=20):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.soft_prompt_length = soft_prompt_length\n",
    "        self.soft_prompt_embed = nn.Embedding(self.soft_prompt_length, config.hidden_size)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        soft_prompt=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        return super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c7f9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\shubh/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\shubh/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: title, __index_level_0__, text. If title, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n",
      "  Number of trainable parameters = 66955010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 1:10:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Configuration saved in ./results\\checkpoint-500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: title, __index_level_0__, text. If title, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: title, __index_level_0__, text. If title, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 05:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Prompt Results: {'eval_loss': 0.0008965786546468735, 'eval_accuracy': 1.0, 'eval_f1': 1.0, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_runtime': 339.5978, 'eval_samples_per_second': 5.889, 'eval_steps_per_second': 0.368, 'epoch': 1.0, 'train_time': 4266.073160409927, 'eval_time': 339.60398745536804}\n"
     ]
    }
   ],
   "source": [
    "soft_prompt_model = SoftPromptModel.from_pretrained(model_checkpoint, num_labels=2)\n",
    "soft_prompt_results = train_and_evaluate(soft_prompt_model, training_args, tokenized_datasets)\n",
    "print(\"Soft Prompt Results:\", soft_prompt_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d67c9d79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\shubh\\anaconda3\\lib\\site-packages (4.29.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "peft 0.11.1 requires huggingface-hub>=0.17.0, but you have huggingface-hub 0.13.4 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: datasets in c:\\users\\shubh\\anaconda3\\lib\\site-packages (2.13.2)\n",
      "Requirement already satisfied: adapter-transformers in c:\\users\\shubh\\anaconda3\\lib\\site-packages (3.2.1.post0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from adapter-transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from adapter-transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from adapter-transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from adapter-transformers) (20.9)\n",
      "Requirement already satisfied: requests in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from adapter-transformers) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from adapter-transformers) (3.0.12)\n",
      "Collecting huggingface-hub<0.14.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from adapter-transformers) (4.66.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from adapter-transformers) (2024.5.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from huggingface-hub<0.14.0,>=0.11.0->adapter-transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from packaging>=20.0->adapter-transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->adapter-transformers) (0.4.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests->adapter-transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests->adapter-transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from requests->adapter-transformers) (2.10)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.23.4\n",
      "    Uninstalling huggingface-hub-0.23.4:\n",
      "      Successfully uninstalled huggingface-hub-0.23.4\n",
      "Successfully installed huggingface-hub-0.13.4\n",
      "Requirement already satisfied: torch in c:\\users\\shubh\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\shubh\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\shubh\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from sklearn) (0.24.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from networkx->torch) (5.0.6)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shubh\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6ecc60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\shubh/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\shubh/.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: title, __index_level_0__, text. If title, __index_level_0__, text are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 8000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n",
      "  Number of trainable parameters = 739586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 35:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.027265</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.994407</td>\n",
       "      <td>0.994407</td>\n",
       "      <td>0.994407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: title, __index_level_0__, text. If title, __index_level_0__, text are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForSequenceClassification.forward` and have been ignored: title, __index_level_0__, text. If title, __index_level_0__, text are not expected by `PeftModelForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 03:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Model Results: {'eval_loss': 0.027265407145023346, 'eval_accuracy': 0.995, 'eval_f1': 0.9944071588366891, 'eval_precision': 0.9944071588366891, 'eval_recall': 0.9944071588366891, 'eval_runtime': 226.1617, 'eval_samples_per_second': 8.843, 'eval_steps_per_second': 0.553, 'epoch': 1.0, 'train_time': 2114.131035089493, 'eval_time': 226.16911149024963}\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Define LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  # Sequence classification task\n",
    "    r=8,                        # Low rank\n",
    "    lora_alpha=32,              # Alpha parameter for LoRA\n",
    "    lora_dropout=0.1,           # Dropout for LoRA\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_lin\", \"v_lin\"] # No bias in LoRA\n",
    ")\n",
    "\n",
    "# Apply LoRA to the base model\n",
    "lora_model = get_peft_model(AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2), lora_config)\n",
    "\n",
    "# Train and evaluate the LoRA model\n",
    "lora_results = train_and_evaluate(lora_model, training_args, tokenized_datasets)\n",
    "print(\"LoRA Model Results:\", lora_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b6ac7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "labels = [\"Base Model\", \"Soft Prompts\", \"LoRA\"]\n",
    "accuracy = [base_results.get(\"eval_accuracy\", 0), soft_prompt_results.get(\"eval_accuracy\", 0), lora_results.get(\"eval_accuracy\", 0)]\n",
    "f1 = [base_results.get(\"eval_f1\", 0), soft_prompt_results.get(\"eval_f1\", 0), lora_results.get(\"eval_f1\", 0)]\n",
    "precision = [base_results.get(\"eval_precision\", 0), soft_prompt_results.get(\"eval_precision\", 0), lora_results.get(\"eval_precision\", 0)]\n",
    "recall = [base_results.get(\"eval_recall\", 0), soft_prompt_results.get(\"eval_recall\", 0), lora_results.get(\"eval_recall\", 0)]\n",
    "train_time = [base_results.get(\"train_time\", 0), soft_prompt_results.get(\"train_time\", 0), lora_results.get(\"train_time\", 0)]\n",
    "eval_time = [base_results.get(\"eval_time\", 0), soft_prompt_results.get(\"eval_time\", 0), lora_results.get(\"eval_time\", 0)]\n",
    "\n",
    "metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'F1 Score': f1,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'Training Time': train_time,\n",
    "    'Evaluation Time': eval_time\n",
    "}\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "for idx, (metric, values) in enumerate(metrics.items()):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    axs[row, col].bar(labels, values, color=colors[idx])\n",
    "    axs[row, col].set_title(metric)\n",
    "    axs[row, col].set_ylim(0, max(values) * 1.2)  # Add some space above the highest bar for clarity\n",
    "    \n",
    "    for i, v in enumerate(values):\n",
    "        axs[row, col].text(i, v + max(values) * 0.02, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xlabel('Model Type')\n",
    "    ax.label_outer()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d6d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
